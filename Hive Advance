Hive Dynamic partitions :-


set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nonstrict
set hive.exec.max.dynamic.partitions.pernode=2000


Hive Map join #


hive.auto.convert.join



To Enforce Bucketing 
hive.enforce.bucketing=true

to perfom join on bucketed table 
hive.optimize.bucketmapjoin=true.




Parallel execution:
SET hive.exec.parallel=true.



 Vectorization

set hive.vectorized.execution = true

set hive.vectorized.execution.enabled = true

#ORC supports compressed (ZLIB and Snappy), as well as uncompressed storage.

file format#

Text File
Sequence File
RC File
AVRO File
ORC File



“1”, “Johny”, “1, NYC”
“2”, “Tim”, “10, DC”

CREATE EXTERNAL TABLE quoted_file(name string, amount int)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
"separatorChar" = ",",
"quoteChar" = "\""
)

STORED AS TEXTFILE
LOCATION '/test';

Parquet File

set hive.support.concuurency=true 
set hive.enforce.nucketing=true
set hive.txn.manager=org.apache.hadoop.ql.lockmgr.DbTxManager

limitations :-

partitioned and bucketing columns cannot be updated 

t should be stored as ORC file format.
2. It should be bucketed.
3. It should support transactions(ACID semantics enabled).







link refrence :-

https://www.qubole.com/blog/hive-best-practices/
http://letsexplorehadoop.blogspot.com/2016/05/upsert-in-hive-3-step-process.html

http://letsexplorehadoop.blogspot.com/2016/06/skew-join-optimization-in-hive.html






